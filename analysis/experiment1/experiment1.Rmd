---
title: "R Notebook"
output: html_notebook
---

# Imports

```{r}
library(tidyverse)
library(tidyboot)
library(ggthemes)

library(lme4)
library(lmerTest)
library(here)
```

# Preprocess raw data

Note: This section requires the raw data downloaded from [Amazon S3](https://emergent-sensing.s3.us-east-2.amazonaws.com/exp1_raw_games.zip) and unzipped into `data/experiment1/`. If you are working with the preprocessed data, skip to the next section.

## Load in raw empirical data

```{r}
# import games and compute avg score for each player
d.exp1.raw <- read_csv(here('data/experiment1/exp1_raw.csv'), show_col_types = F) %>%
  group_by(gameid) %>%
  mutate(half = ifelse(tick < max(tick)/2, 'first', 'second')) 

# get list of incomplete games
incomplete_games <- d.exp1.raw %>% group_by(gameid) %>% summarize(t = max(tick)) %>% filter(t < 2399) %>% pull(gameid)

# get list of pids that disconnected early (in first half)
inactive_pids_firsthalf <- d.exp1.raw %>% group_by(pid) %>% summarize(t = max(tick)) %>% filter(t < 1200) %>% pull(pid)

# get list of pids that went inactive at any point
inactive_pids <- d.exp1.raw %>% group_by(pid) %>% summarize(t = max(tick)) %>% filter(t < 2399) %>% pull(pid)
```

```{r}
d <- d.exp1.raw %>%
  # entirely remove these 11 games that didn't finish
  filter(!(gameid %in% incomplete_games)) %>%
  # get the average scores for each participant in each half
  group_by(gameid, pid, half) %>%
  summarize(avg_score = mean(bg_val)) %>%
  separate('gameid', into = c('date', 'n_players_planned', 'noise', 'gameid'), sep = '_') %>%
  # remove participants who dropped out during the first half 
  # and compute resulting group size for second half
  filter(!(pid %in% inactive_pids_firsthalf)) %>%
  group_by(gameid) %>%
  mutate(n_players = length(unique(pid))) 

write_csv(d, here('data/experiment1/exp1_preprocessed.csv'))
```

```{r}
cat('before exclusions:', 
    d.exp1.raw %>% pull(pid) %>% unique() %>% length(), 'unique participants in', 
    d.exp1.raw %>% pull(gameid) %>% unique() %>% length(), 'unique games')

cat('after exclusions:', 
    d %>% pull(pid) %>% unique() %>% length(), 'unique participants in', 
    d %>% pull(gameid) %>% unique() %>% length(), 'unique games')
```

# Combine empirical with simulation data

## Aggregate empirical data down to group sizes

```{r}
d <- read_csv(here('data/experiment1/exp1_preprocessed.csv'))

# bootstrap second-half scores (using game avg as bootstrap unit)
d.aggregated <- d %>% 
  filter(half == 'second') %>%
  group_by(n_players, gameid) %>% 
  summarize(avg_score = mean(avg_score)) %>%
  group_by(n_players) %>%
  tidyboot_mean(avg_score) %>%
  mutate(src = 'empirical') %>%
  select(-n, -mean) 
```

## Import raw simulation data 

```{r}
# Import aggregated simulation data
d.simulations <- here('simulations/output/predictions-emergent/finals.csv') %>%
  read_csv(show_col_types = F,
           col_names = c('expid', 'pid', 'strategy', 'total_score')) %>%
  separate(expid, into = c('n_players', 'composition', 'rep', 'prob_explore'), sep = '-') %>%
  filter(strategy != 'smart' | as.numeric(prob_explore) <= 0.3) %>%
  filter(as.numeric(n_players) <= 6) 

# pull out mean score for 6 player group as reference point
end_point_means <- d.aggregated %>%
  filter(n_players == 6) %>%
  pull(empirical_stat)

# Find a very informal parameter fit for each model (minimize prediction error at endpoint)
d.modelerror <- d.simulations %>%
  filter(n_players == 6) %>%
  group_by(strategy, prob_explore) %>%
  tidyboot_mean(total_score/2400, nboot = 1) %>%
  mutate(error = abs(empirical_stat - end_point_means))

# Aggregate model predictions 
sim.aggregated <- d.simulations %>%
  group_by(n_players, strategy, prob_explore) %>%
  summarize(empirical_stat = mean(total_score)/2400, n = length(total_score)) %>%
  left_join(d.modelerror %>% select(strategy, prob_explore, error), 
            by = c('strategy', 'prob_explore')) %>%
  group_by(strategy) %>%
  filter(error == min(error, na.rm = T)) %>%
  ungroup() %>%
  mutate(src = paste0('model-', fct_relevel(strategy, 'smart','naive_copy')),
         n_players = as.numeric(n_players)) %>%
  select(n_players, src, empirical_stat)
```
# Compare group size effects

## Generate Figure 1

```{r}
bind_rows(sim.aggregated, d.aggregated)  %>%
  separate(src, sep = '-', into = c('src', 'type')) %>%
  mutate(type = ifelse(is.na(type), 'empirical', type)) %>%
  ggplot(aes(x = n_players, y = empirical_stat, color=type)) +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, data = ) +
    geom_smooth(method = 'lm', formula = y ~ poly(x, 1), se = F) +
    geom_hline(yintercept = 0.15, linetype = 'dashed') +
    theme_few() +
    labs(x = 'number of players', y = 'mean score') +
    ylim(0, 0.3) +
    xlim(0, 7) +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6)) +
    facet_wrap(~ src) +
    theme(aspect.ratio = 1) +
    ggthemes::scale_color_colorblind()

ggsave('./performance-summary-exp1.pdf', width = 6, height = 3, units = 'in', useDingbats = F)
```

## Compute statistics

First, we observe the simple effect of group size in the second half (b=0.99, t = 4.366, p = 1.56e-05).
Second, we observe the main effect where groups of all sizes tend to perform better in the second half. 
Third, we observe an interaction: the effect of group size is only present in the second half. 

```{r}
exp1.reg <- d %>% 
  ungroup() %>%
  mutate(score = scale(100*avg_score, scale = F), 
         n_players = scale(n_players, scale=F)) %>%
  lmer(score ~ n_players * half + (1 + half | gameid) + (1 + n_players || noise), 
       data = .,
       contrasts = list(half=contr.treatment(2, base = 2))) 

summary(exp1.reg)
confint(exp1.reg)
```

```{r}
d %>% filter(half == 'second') %>% group_by(n_players) %>% tidyboot_mean(avg_score)
```

## Validate exploitation

We assume in the model that P(exploit | scoring) ~ 1 - $\epsilon$. 
Here we analyze empirical 'exploitation' rates. 

```{r}
library(broom)
d.exp1.raw %>% 
  filter(!(gameid %in% incomplete_games)) %>%
  left_join(d, by = c('pid', 'half')) %>%
  filter(half == 'second') %>% 
  mutate(bg_val = factor(bg_val)) %>%
  group_by(pid, bg_val) %>%
  summarize(velocity = mean(velocity)) %>%
  spread(bg_val, velocity) %>%
  ungroup() %>%
  summarize(t.test(`0`, `1`) %>% tidy())
```

The effect is similar for different group sizes. 

```{r}
d.exp1.raw %>% 
  filter(!(gameid %in% incomplete_games)) %>%
  left_join(d, by = c('pid', 'half')) %>%
  filter(half == 'second') %>%
  mutate(bg_val = factor(bg_val)) %>%
  group_by(bg_val, pid, n_players) %>%
  summarize(velocity = mean(velocity)) %>%
  mutate(bg_val = ifelse(bg_val == 0, 'reward absent', 'reward present')) %>%
  ggplot(aes(x = velocity, fill = bg_val, color = bg_val)) +
    geom_vline(xintercept = c(0, 2.125, 7.125), linetype = 'dotted') +
    geom_density(alpha = 0.5) +
    labs(x = 'speed', y = 'density', fill = '', color = '') +
    theme_few() +
    facet_wrap(~ paste0('size = ', n_players)) +
    theme(aspect.ratio = 1, legend.position = 'top')

ggsave('./speed.pdf', width = 6, height = 4, units = 'in', useDingbats = F)
```

Another way of quantifying this effect is to look at discrete events where participants change their speed. When reward is present, 75% of speed changes involve slowing down. When reward is absent, the inverse is true: a slim majority of speed changes (56%) involve speeding up. 

```{r}
d.exp1.raw %>% 
  group_by(pid) %>%
  filter(half == 'second') %>%
  mutate(bg_val = factor(bg_val), velocity = velocity,
         prev_velocity = lag(velocity),
         change = prev_velocity != velocity) %>%
  filter(change) %>%
  group_by(bg_val) %>%
  mutate(total = n()) %>%
  group_by(bg_val, velocity < prev_velocity) %>%
  summarize(n = n(), prop = n/mean(total))
```

```{r}

```

```{r}
d.exp1.raw %>% 
  filter(half == 'second') %>%
  mutate(bg_val = factor(bg_val)) %>%
  group_by(bg_val, pid) %>%
  summarize(stopped = min(velocity)) %>%
  mutate(bg_val = ifelse(bg_val == 0, 'reward absent', 'reward present'),
         velocity = ifelse(velocity == 0, 'stopped', ifelse(velocity == '2.125', 'normal', 'fast'))) %>%
  ggplot(aes(x = bg_val, y = prop * 100, fill = velocity)) +
    geom_bar(stat = 'identity') +
    scale_fill_colorblind() +
    labs(x = '', y = '% time') +
    theme_few()
```

# Supplemental figs

with raw (tick-level) data

```{r}
read_csv(here('data/experiment1/all_raw_games.csv'), show_col_types = F) %>%
  group_by(gameid) %>%
  mutate(n_players = length(unique(pid)),
         half = ifelse(tick < max(tick)/2, 'first', 'second'),
         quartile = floor(4 * (tick-1) / max(tick) )) %>%
  group_by(n_players, tick) %>%
  summarize(m = mean(bg_val)) %>%
  ungroup() %>%
  ggplot(aes(x = tick, y = m, color = n_players, group = n_players)) +
    geom_point(alpha = 0.02) +
    geom_hline(yintercept = 0.15) +
    geom_smooth(method = 'loess', span = .8) +
    theme_few()
```

boxplot style

```{r}
d %>%
  ggplot(aes(x = factor(n_players), y = avg_score, color = half)) +
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(alpha = 0.15, position = position_jitterdodge(jitter.width = 0.2)) +
    theme_few() +
    ylab("mean score") +
    xlab("number of players") +
    ylim(0, 0.5) +
    theme(aspect.ratio = 2/3) +
    ggthemes::scale_color_colorblind()
```
